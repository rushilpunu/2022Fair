{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom matplotlib import pyplot as plt\nimport math, os, re, warnings, random\nfrom sklearn.utils import class_weight\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom tensorflow.keras import optimizers, applications, Sequential, losses, metrics\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,LearningRateScheduler","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:30.783667Z","iopub.execute_input":"2022-05-05T15:26:30.784189Z","iopub.status.idle":"2022-05-05T15:26:32.991282Z","shell.execute_reply.started":"2022-05-05T15:26:30.784088Z","shell.execute_reply":"2022-05-05T15:26:32.990562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n    \n    \nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:32.992387Z","iopub.execute_input":"2022-05-05T15:26:32.992819Z","iopub.status.idle":"2022-05-05T15:26:32.998277Z","shell.execute_reply.started":"2022-05-05T15:26:32.992787Z","shell.execute_reply":"2022-05-05T15:26:32.997178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.get_strategy()\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync \nprint('# REPLICAS: {}'.format(REPLICAS))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:32.999889Z","iopub.execute_input":"2022-05-05T15:26:33.000168Z","iopub.status.idle":"2022-05-05T15:26:33.01435Z","shell.execute_reply.started":"2022-05-05T15:26:33.000141Z","shell.execute_reply":"2022-05-05T15:26:33.013372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32 * REPLICAS\nLEARNING_RATE = 3e-5 * REPLICAS\nEPOCHS = 35\nHEIGHT = 300\nWIDTH = 300\nCHANNELS = 3\nES_PATIENCE = 10\nAUG_BATCH=BATCH_SIZE\nIMAGE_SIZE=[HEIGHT,WIDTH]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.015806Z","iopub.execute_input":"2022-05-05T15:26:33.016377Z","iopub.status.idle":"2022-05-05T15:26:33.027529Z","shell.execute_reply.started":"2022-05-05T15:26:33.016339Z","shell.execute_reply":"2022-05-05T15:26:33.026497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GCS_PATH = KaggleDatasets().get_gcs_path('leukemia-classification')\nGCS_PATH = '../input/leukemia-classification/'","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.029025Z","iopub.execute_input":"2022-05-05T15:26:33.029449Z","iopub.status.idle":"2022-05-05T15:26:33.048213Z","shell.execute_reply.started":"2022-05-05T15:26:33.029384Z","shell.execute_reply":"2022-05-05T15:26:33.047225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataset_0_all = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_0/all/*.bmp')\ntrain_dataset_0_hem = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_0/hem/*.bmp')\ntrain_dataset_1_all = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_1/all/*.bmp')\ntrain_dataset_1_hem = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_1/hem/*.bmp')\ntrain_dataset_2_all = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_2/all/*.bmp')\ntrain_dataset_2_hem = glob.glob(GCS_PATH + '/C-NMC_Leukemia/training_data/fold_2/hem/*.bmp')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.049787Z","iopub.execute_input":"2022-05-05T15:26:33.05022Z","iopub.status.idle":"2022-05-05T15:26:33.102756Z","shell.execute_reply.started":"2022-05-05T15:26:33.050175Z","shell.execute_reply":"2022-05-05T15:26:33.101731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset_0_all)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.104074Z","iopub.execute_input":"2022-05-05T15:26:33.104386Z","iopub.status.idle":"2022-05-05T15:26:33.111873Z","shell.execute_reply.started":"2022-05-05T15:26:33.104354Z","shell.execute_reply":"2022-05-05T15:26:33.110841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Include Validation data as well :-\ntest_data=pd.read_csv(GCS_PATH + '/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv')\n\nat = test_data[test_data['labels'] == 1]\nht = test_data[test_data['labels'] == 0]\n\ntest_PATH = GCS_PATH + '/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data/'\nATL = [test_PATH +  i for i in list(at.new_names)]\nHTL = [test_PATH +  i for i in list(ht.new_names)]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.113078Z","iopub.execute_input":"2022-05-05T15:26:33.11334Z","iopub.status.idle":"2022-05-05T15:26:33.139907Z","shell.execute_reply.started":"2022-05-05T15:26:33.113312Z","shell.execute_reply":"2022-05-05T15:26:33.139067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging happens here:-\nA=[]\nH=[]\nA.extend(train_dataset_0_all)\nA.extend(train_dataset_1_all)\nA.extend(train_dataset_2_all)\n\nH.extend(train_dataset_0_hem)\nH.extend(train_dataset_1_hem)\nH.extend(train_dataset_2_hem)\n\nprint(len(A))\nprint(len(H))\n\n# Create labels :-\nLabel_A = [1]*len(A)\nLabel_H = [0]*len(H)\n\n# Converting to pandas dataframe for easier access:-\nA.extend(H)\nLabel_A.extend(Label_H)\ndf = pd.DataFrame({'path':A, 'label':Label_A})\ndf = df.sample(frac=1).reset_index(drop=True)\n\nFILENAMES = df['path']\nLABELS = df['label']\n\nprint('Final Merged Data:-')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.143684Z","iopub.execute_input":"2022-05-05T15:26:33.144162Z","iopub.status.idle":"2022-05-05T15:26:33.174089Z","shell.execute_reply.started":"2022-05-05T15:26:33.144127Z","shell.execute_reply":"2022-05-05T15:26:33.173139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cw = class_weight.compute_class_weight('balanced',\n                                        np.unique(LABELS),\n                                        LABELS)\ncw = {0:cw[0], 1:cw[1]}","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.175919Z","iopub.execute_input":"2022-05-05T15:26:33.1762Z","iopub.status.idle":"2022-05-05T15:26:33.183639Z","shell.execute_reply.started":"2022-05-05T15:26:33.176173Z","shell.execute_reply":"2022-05-05T15:26:33.182706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cw","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.184717Z","iopub.execute_input":"2022-05-05T15:26:33.185091Z","iopub.status.idle":"2022-05-05T15:26:33.199326Z","shell.execute_reply.started":"2022-05-05T15:26:33.185058Z","shell.execute_reply":"2022-05-05T15:26:33.198458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Augmentation function:-\ndef data_augment(image, label):\n    \n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel = tf.random.uniform([], 0, 1.0, dtype=tf.float32)    \n    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_flip_left_right(image)\n    \n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    if p_pixel >= .2:\n        if p_pixel >= .8:\n            image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n        elif p_pixel >= .6:\n            image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n        elif p_pixel >= .4:\n            image = tf.image.random_brightness(image, max_delta=.1)\n        else:\n            image = tf.image.adjust_gamma(image, gamma=.6)\n            \n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.6)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.8)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n        \n    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.200601Z","iopub.execute_input":"2022-05-05T15:26:33.200974Z","iopub.status.idle":"2022-05-05T15:26:33.211375Z","shell.execute_reply.started":"2022-05-05T15:26:33.200945Z","shell.execute_reply":"2022-05-05T15:26:33.21062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(filename,label):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_bmp(image)\n    image = tf.image.convert_image_dtype(image, tf.float32) /  0.45 \n    image = tf.image.resize(image, IMAGE_SIZE)\n    return image, tf.one_hot(label,2)\n\ndef load_dataset(filenames, labels ,ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(parse_data, num_parallel_calls=AUTO)\n    return dataset\n\ndef get_dataset(FILENAMES,LABELS, ordered=False, repeated=False, augment=False):\n    dataset = load_dataset(FILENAMES, LABELS, ordered=ordered)\n    if augment:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    if repeated:\n        dataset = dataset.repeat()\n    if not ordered:\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.212305Z","iopub.execute_input":"2022-05-05T15:26:33.212723Z","iopub.status.idle":"2022-05-05T15:26:33.223822Z","shell.execute_reply.started":"2022-05-05T15:26:33.212694Z","shell.execute_reply":"2022-05-05T15:26:33.223077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nnp.set_printoptions(threshold=15, linewidth=80)\nCLASSES = [0,1]\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    labels = [str(i) for i in  numpy_labels]\n\n    return numpy_images, labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = label\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        # image = cv2.imdecode(image,cv2.IMREA)\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    \n    \n# Model evaluation\ndef plot_metrics(history):\n    metric_list = [m for m in list(history.keys()) if m is not 'lr']\n    size = len(metric_list)//2\n    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 4))\n    if size > 1:\n        axes = axes.flatten()\n    else:\n        axes = [axes]\n    \n    for index in range(len(metric_list)//2):\n        metric_name = metric_list[index]\n        val_metric_name = metric_list[index+size]\n        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\n        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\n        axes[index].legend(loc='best', fontsize=16)\n        axes[index].set_title(metric_name)\n        if 'loss' in metric_name:\n            axes[index].axvline(np.argmin(history[metric_name]), linestyle='dashed')\n            axes[index].axvline(np.argmin(history[val_metric_name]), linestyle='dashed', color='orange')\n        else:\n            axes[index].axvline(np.argmax(history[metric_name]), linestyle='dashed')\n            axes[index].axvline(np.argmax(history[val_metric_name]), linestyle='dashed', color='orange')\n\n    plt.xlabel('Epochs', fontsize=16)\n    sns.despine()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:33.22483Z","iopub.execute_input":"2022-05-05T15:26:33.225222Z","iopub.status.idle":"2022-05-05T15:26:33.24423Z","shell.execute_reply.started":"2022-05-05T15:26:33.225191Z","shell.execute_reply":"2022-05-05T15:26:33.243511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset(FILENAMES[:60],LABELS[:60], ordered=True,augment=True)\ntrain_iter = iter(train_dataset.unbatch().batch(20))\n\ndisplay_batch_of_images(next(train_iter))\ndisplay_batch_of_images(next(train_iter))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:53.548585Z","iopub.execute_input":"2022-05-05T15:27:53.549203Z","iopub.status.idle":"2022-05-05T15:27:59.238973Z","shell.execute_reply.started":"2022-05-05T15:27:53.549168Z","shell.execute_reply":"2022-05-05T15:27:59.237681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cosine Annealing:-\nLR_START = 1e-8\nLR_MIN = 1e-8\nLR_MAX = LEARNING_RATE\nLR_RAMPUP_EPOCHS = 3\nLR_SUSTAIN_EPOCHS = 0\nN_CYCLES = .5\n\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        progress = (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) / (EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\n        lr = LR_MAX * (0.5 * (1.0 + tf.math.cos(math.pi * N_CYCLES * 2.0 * progress)))\n        if LR_MIN is not None:\n            lr = tf.math.maximum(LR_MIN, lr)\n            \n    return lr\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\n\nsns.set(style='whitegrid')\nfig, ax = plt.subplots(figsize=(20, 6))\nplt.plot(rng, y)\n\n# print(f'{EPOCHS} total epochs and {NUM_TRAINING_IMAGES//BATCH_SIZE} steps per epoch')\nprint(f'Learning rate schedule: {y[0]:.3g} to {max(y):.3g} to {y[-1]:.3g}')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:37.663453Z","iopub.execute_input":"2022-05-05T15:26:37.663715Z","iopub.status.idle":"2022-05-05T15:26:37.916401Z","shell.execute_reply.started":"2022-05-05T15:26:37.663688Z","shell.execute_reply":"2022-05-05T15:26:37.915435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:37.919184Z","iopub.execute_input":"2022-05-05T15:26:37.919484Z","iopub.status.idle":"2022-05-05T15:26:37.962539Z","shell.execute_reply.started":"2022-05-05T15:26:37.919456Z","shell.execute_reply":"2022-05-05T15:26:37.961548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Architecture :-\ndef model_fn(input_shape, N_CLASSES):\n    input_image = L.Input(shape=input_shape, name='input_image')\n    base_model = tf.keras.applications.InceptionV3(input_tensor=input_image, \n                                    include_top=False, \n                                    weights='imagenet', \n                                    pooling='avg')\n\n    for layer in base_model.layers:\n        if 'bn' in layer.name:\n            layer.trainable = False\n        else:\n            layer.trainable = True\n            \n    model = tf.keras.Sequential([\n        base_model,\n        L.Dropout(.25),\n        L.Dense(N_CLASSES, activation='sigmoid', name='output')\n    ])\n\n    optimizer = optimizers.Adam(lr=LEARNING_RATE)\n    model.compile(optimizer=optimizer, \n                  loss='binary_crossentropy', \n                  metrics=['accuracy',tfa.metrics.F1Score(num_classes=2, average='weighted')])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:37.966187Z","iopub.execute_input":"2022-05-05T15:26:37.966558Z","iopub.status.idle":"2022-05-05T15:26:37.975209Z","shell.execute_reply.started":"2022-05-05T15:26:37.96652Z","shell.execute_reply":"2022-05-05T15:26:37.973951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross Validated training loop:-\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\noof_pred = []; oof_labels = []; history_list = []\ncv1 = cv2 = 0\n\n\nfor fold,(idxT, idxV) in enumerate(skf.split(FILENAMES,LABELS)):\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {len(idxT)} VALID: {len(idxV)}')\n    STEPS_PER_EPOCH = len(idxT) // BATCH_SIZE\n    \n    \n    K.clear_session()\n    with strategy.scope():\n        model = model_fn((None, None, CHANNELS), 2)\n        \n    model_path = f'model_{fold}.h5'\n    es = EarlyStopping(monitor='val_f1_score', mode='max', \n                    patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n\n    ## TRAIN\n    history = model.fit(x=get_dataset(FILENAMES[idxT],LABELS[idxT], ordered=False, repeated=True, augment=True), \n                        validation_data=get_dataset(FILENAMES[idxV],LABELS[idxV] , ordered=True, repeated=False, augment=False), \n                        steps_per_epoch=STEPS_PER_EPOCH, \n                        callbacks=[es, LearningRateScheduler(lrfn ,verbose=0)], \n                        epochs=EPOCHS,  \n                        verbose=1,\n                        class_weight = cw).history\n      \n    model.save_weights(model_path)\n    history_list.append(history)\n    # Save last model weights\n\n    \n    ## RESULTS\n    print(f\"#### FOLD {fold+1} Accuracy = {np.max(history['accuracy']):.3f}\")\n    print(f\"#### FOLD {fold+1} F1_score = {np.max(history['f1_score']):.3f}\")\n    cv1 += np.max(history['accuracy'])\n    cv2 += np.max(history['f1_score'])\n    \n    \nprint(f'### Avg. Accuracy = {cv1/3.0} \\n ### Avg. Weighted F1 = {cv2/3.0}')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:26:37.976802Z","iopub.execute_input":"2022-05-05T15:26:37.977442Z","iopub.status.idle":"2022-05-05T15:27:00.144259Z","shell.execute_reply.started":"2022-05-05T15:26:37.977374Z","shell.execute_reply":"2022-05-05T15:27:00.141939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot metrics:-\nfor fold, history in enumerate(history_list):\n    print(f'\\nFOLD: {fold+1}')\n    plot_metrics(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.145208Z","iopub.status.idle":"2022-05-05T15:27:00.145601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TA=[]\nTH=[]\n\nTA.extend(ATL)\nTH.extend(HTL)\n\nprint(len(TA))\nprint(len(TH))\n\n# Create labels :-\nLabel_TA = [1]*len(TA)\nLabel_TH = [0]*len(TH)\n\n# Converting to pandas dataframe for easier access:-\nTA.extend(TH)\nLabel_TA.extend(Label_TH)\ntdf = pd.DataFrame({'path':TA, 'label':Label_TA})\ntdf = tdf.sample(frac=1).reset_index(drop=True)\nTFILENAMES = tdf['path']\nTLABELS = tdf['label']\n\n\nprint('Test Merged Data:-')\ntdf","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.146501Z","iopub.status.idle":"2022-05-05T15:27:00.146851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = get_dataset(TFILENAMES[:1867],TLABELS[:1867], ordered=True,augment=True)\ntest_iter = iter(train_dataset.unbatch().batch(20))\n\ndisplay_batch_of_images(next(test_iter))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.147628Z","iopub.status.idle":"2022-05-05T15:27:00.147975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accu = model.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.148676Z","iopub.status.idle":"2022-05-05T15:27:00.149026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nfrom PIL import Image\nim1 = Image.open(GCS_PATH + '/C-NMC_Leukemia/testing_data/C-NMC_test_final_phase_data/1105.bmp')\np1 = np.array(im1)\nplt.imshow(p1)\np1 = np.expand_dims(p1, axis=0)\np1.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.149724Z","iopub.status.idle":"2022-05-05T15:27:00.150078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(p1)\nprediction = np.argmax(preds)\npct = np.max(preds)\nif prediction == 0:\n    print('The Prediction of the sample is: It Is ALL')\nelse:\n    print('Prediction is Hem')\nprint(\"Prediction Confidence Percentage is: \", pct*100)\nplt.imshow(im1);","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.150997Z","iopub.status.idle":"2022-05-05T15:27:00.151343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lime.wrappers.scikit_image import SegmentationAlgorithm\nfrom skimage.segmentation import mark_boundaries\n \nsegmentation_fn = SegmentationAlgorithm(\n    'slic',\n    kernel_size=4,\n    max_dist=200,\n    ratio=0.2,\n    random_seed=42\n)\n\nsegments = segmentation_fn(im1)\n\nprint(len(np.unique(segments)))\n\nplt.imshow(segments)\nplt.colorbar();","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.152186Z","iopub.status.idle":"2022-05-05T15:27:00.152546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(mark_boundaries(np.array(im1), segments));","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.153178Z","iopub.status.idle":"2022-05-05T15:27:00.153531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lime import lime_image\n\nexplainer = lime_image.LimeImageExplainer()\nexplanation = explainer.explain_instance(np.array(im1), model.predict,  \n                                         top_labels=3, hide_color=0, num_samples=1000)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.154383Z","iopub.status.idle":"2022-05-05T15:27:00.154752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.segmentation import mark_boundaries\n\n\ntemp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=3, hide_rest=True)\ntemp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=False, num_features=3, hide_rest=False)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\nax1.imshow(mark_boundaries(temp_1, mask_1))\nax2.imshow(mark_boundaries(temp_2, mask_2));\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:27:00.155491Z","iopub.status.idle":"2022-05-05T15:27:00.155837Z"},"trusted":true},"execution_count":null,"outputs":[]}]}